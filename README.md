# Deep-Neural-Network-from-scratch
Implementation of a flexible L-layer deep neural network from scratch using numpy. The activation functions used are  - relu,sigmoid and softmax. Applied to two different datasets (IRIS, Breast Cancer detection) to test the funtionality of the net.

